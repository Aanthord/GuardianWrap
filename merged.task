package main

import (
    "fmt"
    "log"
    "net/http"
    "os"
    "os/signal"
    "syscall"
    "github.com/gorilla/mux"
    "github.com/gorilla/websocket"
    "github.com/iovisor/gobpf/bcc"
)

// Load and attach the eBPF program to the tracepoint for execve system calls.
func loadEBPFProgram() {
    source, err := os.ReadFile("exec_logger.c")
    if err != nil {
        fmt.Fprintf(os.Stderr, "Failed to read eBPF program source: %s\n", err)
        os.Exit(1)
    }

    m := bcc.NewModule(string(source), []string{})
    defer m.Close()

    tp, err := m.LoadTracepoint("log_exec")
    if err != nil {
        fmt.Fprintf(os.Stderr, "Failed to load exec logger tracepoint: %s\n", err)
        os.Exit(1)
    }

    err = m.AttachTracepoint("syscalls:sys_enter_execve", tp)
    if err != nil {
        fmt.Fprintf(os.Stderr, "Failed to attach to execve tracepoint: %s\n", err)
        os.Exit(1)
    }

    fmt.Println("eBPF program loaded and attached.")
}

// WebSocket handler for streaming eBPF events to a web client.
func eventWebSocket(w http.ResponseWriter, r *http.Request) {
    upgrader := websocket.Upgrader{
        ReadBufferSize:  1024,
        WriteBufferSize: 1024,
    }

    conn, err := upgrader.Upgrade(w, r, nil)
    if err != nil {
        log.Println(err)
        return
    }
    defer conn.Close()

    alertChannel := make(chan Alert)
    go alertWebSocket(conn, alertChannel)

    // Imagine this loop listens for new eBPF events and sends them to the client.
    for {
        event := getNextEvent()
        if err := conn.WriteJSON(event); err != nil {
            log.Println(err)
            break
        }
    }
}

// Separate goroutine for handling alerts and sending them over the same WebSocket connection.
func alertWebSocket(conn *websocket.Conn, alertChannel <-chan Alert) {
    for alert := range alertChannel {
        if err := conn.WriteJSON(alert); err != nil {
            log.Println("Error sending alert over WebSocket:", err)
            break
        }
    }
}

// Alert struct for demonstration purposes.
type Alert struct {
    Type    string `json:"type"`
    Message string `json:"message"`
}

func main() {
    loadEBPFProgram()

    // Setting up an HTTP server and routes for querying eBPF events.
    router := mux.NewRouter()
    router.HandleFunc("/events/ws", eventWebSocket).Methods("GET")

    log.Println("HTTP server started on :8080")
    err := http.ListenAndServe(":8080", router)
    if err != nil {
        log.Fatal("ListenAndServe: ", err)
    }

    // Graceful shutdown handling.
    sig := make(chan os.Signal, 1)
    signal.Notify(sig, os.Interrupt, syscall.SIGTERM)
    <-sig

    fmt.Println("Exiting...")
}

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>GuardianWrap Event Viewer</title>
    <style>
        body { font-family: Arial, sans-serif; }
        #events { margin-top: 20px; }
    </style>
</head>
<body>
    <h1>GuardianWrap Event Viewer</h1>
    <div id="status">Connecting to WebSocket...</div>
    <div id="events"></div>

    <script>
        const statusDiv = document.getElementById('status');
        const eventsDiv = document.getElementById('events');

        // Assuming the WebSocket server is running on the same host and port 8080
        const ws = new WebSocket('ws://' + window.location.hostname + ':8080/events/ws');

        ws.onopen = function() {
            statusDiv.textContent = 'Connected to WebSocket.';
        };

        ws.onmessage = function(event) {
            console.log('Message from server:', event.data);
            const eventData = JSON.parse(event.data);

            // Display the event or alert data
            const eventElement = document.createElement('div');
            if (eventData.type && eventData.message) {
                // It's an alert
                eventElement.innerHTML = `<strong>Alert:</strong> ${eventData.type} - ${eventData.message}`;
            } else {
                // Assuming it's a generic event
                eventElement.textContent = `Event: ${event.data}`;
            }
            eventsDiv.appendChild(eventElement);
        };

        ws.onerror = function(error) {
            console.error('WebSocket Error:', error);
            statusDiv.textContent = 'WebSocket error. See console for details.';
        };

        ws.onclose = function() {
            statusDiv.textContent = 'WebSocket connection closed.';
        };
    </script>
</body>
</html>

#include "logger.h"
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/types.h>
#include <sys/wait.h>
#include <signal.h>

#define CRITICAL_SECURITY_BREACH 1
#define BUFFER_OVERFLOW_DETECTED 2
#define SUSPICIOUS_ACTIVITY 3

// Forward declarations
void handle_monitoring_alert(int alert_type);
void shutdown_application();
void restart_application(const char *appName, char *const argv[]);
void notify_administrator(const char *message);
void increase_logging_level();

pid_t targetAppPid = -1; // Assume this is set when the monitored application is launched

void handle_monitoring_alert(int alert_type) {
    switch (alert_type) {
        case CRITICAL_SECURITY_BREACH:
            log_message("Critical security breach detected. Shutting down application.");
            shutdown_application();
            notify_administrator("Critical security breach detected. Application shutdown.");
            break;
        case BUFFER_OVERFLOW_DETECTED:
            log_message("Buffer overflow detected. Attempting to restart application.");
            restart_application("target_application", NULL); // Placeholder, adjust as necessary
            notify_administrator("Buffer overflow detected. Application restarted.");
            break;
        case SUSPICIOUS_ACTIVITY:
            log_message("Suspicious activity detected. Increasing logging level.");
            increase_logging_level();
            break;
        default:
            log_message("Unknown alert type received.");
            break;
    }
}

void shutdown_application() {
    if (targetAppPid != -1) {
        kill(targetAppPid, SIGTERM); // Attempt to terminate the application gracefully
        waitpid(targetAppPid, NULL, 0); // Wait for the application to terminate
    }
}

void restart_application(const char *appName, char *const argv[]) {
    shutdown_application(); // Ensure the application is terminated first
    // Assuming appName and argv are correctly set up for the target application
    pid_t pid = fork();
    if (pid == 0) {
        // Child process: execute the target application
        if (execvp(appName, argv) == -1) {
            perror("Failed to restart application");
            exit(EXIT_FAILURE);
        }
    } else if (pid > 0) {
        targetAppPid = pid; // Update global PID for the new instance of the application
    } else {
        log_message("Failed to fork while attempting to restart application.");
    }
}

void notify_administrator(const char *message) {
    // Simplified example: could be an email, SNMP trap, or a message to a monitoring dashboard
    printf("ADMIN ALERT: %s\n", message);
}

void increase_logging_level() {
    // This function would interface with the logging system to increase verbosity
    // Placeholder for demonstration purposes
    log_message("Logging level increased.");
}

#include "utils.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

char* bytes_to_hex(const uint8_t* bytes, size_t len) {
    char* hex_string = malloc((len * 2) + 1);
    for (size_t i = 0; i < len; i++) {
        sprintf(hex_string + (i * 2), "%02x", bytes[i]);
    }
    hex_string[len * 2] = '\0';
    return hex_string;
}

void register_signal_handlers(void (*handler)(int)) {
    // Example for SIGINT
    if (signal(SIGINT, handler) == SIG_ERR) {
        fprintf(stderr, "Cannot handle SIGINT!\n");
        exit(EXIT_FAILURE);
    }
    // Additional signals could be registered here
}

#include <stdio.h>  // Standard I/O for file operations
#include <stdlib.h> // Standard library for exit

// Function to append data to an immutable log file
void immutable_append(const char *data) {
    // Open the log file in append mode to ensure data is only added
    FILE *fp = fopen("immutable_log.txt", "a");
    if (fp == NULL) {
        perror("Failed to open immutable log file"); // Error handling if file cannot be opened
        exit(EXIT_FAILURE); // Exit the program on failure
    }

    fprintf(fp, "%s\n", data); // Append the data to the file with a newline
    fclose(fp); // Close the file after appending
}

#include "dumper.h" // Include the header file for declarations
#include <stdio.h>  // Standard I/O for file operations
#include <stdlib.h> // Standard library for memory allocation
#include <execinfo.h> // For backtrace functionality
#include <fcntl.h>  // For file control operations like open
#include <unistd.h> // For close function

void collect_stack_dump() {
    void *array[20]; // Increase stack frame capture depth
    size_t size; // To store the number of stack frames captured
    char **strings; // For storing the symbols (function names) of stack frames
    int fd; // File descriptor for the stack dump file

    // Open the stack dump file with write, create, and append options
    fd = open("stack_dump.txt", O_WRONLY|O_CREAT|O_APPEND, 0644);
    if (fd < 0) {
        perror("Failed to open stack dump file"); // Error handling
        return;
    }

    size = backtrace(array, sizeof(array) / sizeof(void*)); // Capture stack frames
    strings = backtrace_symbols(array, size); // Convert addresses to strings

    if (strings != NULL) {
        for (size_t i = 0; i < size; i++) {
            dprintf(fd, "%s\n", strings[i]); // Write each symbol to file
        }
        free(strings); // Free the allocated memory for symbols
    }

    close(fd); // Close the file descriptor
}

#include "logger.h"
#include "blake3.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <time.h>

FILE *log_file = NULL;
const char *log_file_path = "application.log";

void init_logger() {
    log_file = fopen(log_file_path, "a");
    if (!log_file) {
        perror("Failed to open log file");
        exit(EXIT_FAILURE);
    }
}

void log_message(const char *message) {
    if (!log_file) {
        fprintf(stderr, "Logger not initialized\n");
        return;
    }

    // Timestamp for the log entry
    time_t now = time(NULL);
    char *time_str = ctime(&now);
    time_str[strlen(time_str) - 1] = '\0'; // Remove newline

    // Compute BLAKE3 hash
    uint8_t hash[BLAKE3_OUT_LEN];
    blake3_hasher hasher;
    blake3_hasher_init(&hasher);
    blake3_hasher_update(&hasher, (const uint8_t *)message, strlen(message));
    blake3_hasher_finalize(&hasher, hash, sizeof(hash));

    // Convert hash to hex string
    char hex_hash[BLAKE3_OUT_LEN * 2 + 1];
    for (size_t i = 0; i < BLAKE3_OUT_LEN; ++i) {
        sprintf(&hex_hash[i * 2], "%02x", hash[i]);
    }

    // Log with structured format: timestamp, hash, and message
    fprintf(log_file, "[%s] %s %s\n", time_str, hex_hash, message);
    fflush(log_file); // Ensure log entry is written immediately
}

void close_logger() {
    if (log_file) {
        fclose(log_file);
        log_file = NULL;
    }
}

#include "logger.h"
#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/wait.h>
#include <signal.h>

void setup_canary_monitoring();
void perform_cleanup();
void handle_child_process(char *const argv[]);
void signal_handler(int sig);
void register_signal_handlers();

volatile sig_atomic_t child_exited = 0;

int main(int argc, char *argv[]) {
    if (argc < 2) {
        fprintf(stderr, "Usage: %s <application> [args...]\n", argv[0]);
        return EXIT_FAILURE;
    }

    init_logger();
    log_message("Guardian Wrapper initiated.");

    setup_canary_monitoring();
    register_signal_handlers();

    pid_t pid = fork();
    if (pid == 0) {
        // Child process
        handle_child_process(&argv[1]);
    } else if (pid > 0) {
        // Parent process
        int status;
        while (!child_exited) {
            pause(); // Wait for signals
        }
        waitpid(pid, &status, 0); // Collect child's exit status
        if (WIFEXITED(status)) {
            log_message("Application exited normally.");
        } else {
            log_message("Application terminated unexpectedly.");
        }
    } else {
        // Fork failed
        perror("Failed to fork");
        perform_cleanup();
        close_logger();
        return EXIT_FAILURE;
    }

    perform_cleanup();
    close_logger();
    return EXIT_SUCCESS;
}

void setup_canary_monitoring() {
    log_message("Stack canary monitoring setup initiated.");
}

void perform_cleanup() {
    log_message("Performing cleanup operations.");
}

void handle_child_process(char *const argv[]) {
    if (execvp(argv[0], argv) == -1) {
        perror("Error launching application");
        exit(EXIT_FAILURE);
    }
}

void signal_handler(int sig) {
    switch (sig) {
        case SIGCHLD:
            child_exited = 1;
            break;
        // Handle other signals as needed
        default:
            break;
    }
}

void register_signal_handlers() {
    struct sigaction sa;
    sa.sa_handler = signal_handler;
    sigemptyset(&sa.sa_mask);
    sa.sa_flags = 0;

    if (sigaction(SIGCHLD, &sa, NULL) == -1) {
        perror("Error registering signal handler");
        exit(EXIT_FAILURE);
    }
    // Register other signal handlers as needed
}

#ifndef IMMUTABLE_LOGGER_H
#define IMMUTABLE_LOGGER_H

// This inclusion guard prevents the header from being processed
// multiple times, which is essential for preventing redefinition errors

// Declaration of the immutable_append function
// This function is designed to append data to an immutable log file.
// It ensures that once data is written, it cannot be modified or deleted,
// adhering to the principles of immutability for log data.
void immutable_append(const char *data);

#endif // IMMUTABLE_LOGGER_H
// End of the inclusion guard

#ifndef UTILS_H
#define UTILS_H

char* bytes_to_hex(const uint8_t* bytes, size_t len);
void register_signal_handlers(void (*handler)(int));

#endif // UTILS_H

#ifndef LOGGER_H
#define LOGGER_H

#include <stdint.h> // For uint8_t

void init_logger();
void log_message(const char *message);
void close_logger();

#endif // LOGGER_H

#ifndef MONITOR_H
#define MONITOR_H

// Define alert types for different monitoring scenarios
#define CRITICAL_SECURITY_BREACH 1
#define BUFFER_OVERFLOW_DETECTED 2
#define SUSPICIOUS_ACTIVITY 3

#ifdef __cplusplus
extern "C" {
#endif

/**
 * Initializes the stack canary monitoring system.
 * This function should set up any necessary data structures or monitoring threads.
 */
void setup_canary_monitoring();

/**
 * Handles alerts generated by the monitoring system.
 * @param alert_type The type of alert detected, based on predefined constants.
 */
void handle_monitoring_alert(int alert_type);

/**
 * Shuts down the application being monitored.
 * This function attempts to terminate the application gracefully.
 */
void shutdown_application();

/**
 * Attempts to restart the application after it has been shut down.
 * @param appName The name or path of the application executable.
 * @param argv The arguments to pass to the application on restart. Can be NULL if not needed.
 */
void restart_application(const char *appName, char *const argv[]);

/**
 * Sends a notification to the system administrator or responsible party.
 * @param message The message or information about the alert.
 */
void notify_administrator(const char *message);

/**
 * Increases the logging level of the system.
 * This function is a placeholder and should be integrated with the actual logging system.
 */
void increase_logging_level();

#ifdef __cplusplus
}
#endif

#endif // MONITOR_H

#ifndef DUMPER_H
#define DUMPER_H

// Standard guard against multiple inclusions
// Prevents redefinition errors during compilation

// Declaration of the function to collect and record stack dumps
// This function is implemented in dumper.c and can be called from
// other parts of the program to capture the current stack trace
void collect_stack_dump();

#endif // DUMPER_H
// End of the standard inclusion guard

# Guardian Wrapper Project Overview

The Guardian Wrapper Project enhances Linux application security through advanced monitoring techniques. It includes stack canary monitoring to detect buffer overflows, secure logging with BLAKE3 hashing for log integrity, and dynamic response mechanisms for real-time security incident handling.

## Project Objectives

- **Enhance Application Security:** Monitor applications in real-time for security breaches and respond dynamically to threats.
- **Secure Logging:** Implement secure logging mechanisms using BLAKE3 hashing to ensure log integrity.
- **Automated Response:** Develop automated response strategies for various security incidents, enhancing application resilience.

## Project Components and Progress

1. **Stack Canary Monitoring**
   - **Objective:** Detect memory corruption incidents like buffer overflows.
   - **Progress:** 70% complete. Basic structure implemented, pending final testing and integration.

2. **Secure Logging System**
   - **Objective:** Securely log application activities, incorporating BLAKE3 hashing.
   - **Progress:** 80% complete. Implementation in place, pending optimizations and enhancements.

3. **Dynamic Response Mechanisms**
   - **Objective:** Automate responses to monitoring alerts for robust incident handling.
   - **Progress:** 75% complete. Actions defined and partially implemented, awaiting full integration.

4. **Utility Functions**
   - **Objective:** Provide essential utility functions for the project, such as signal handling.
   - **Progress:** 90% complete. Core utilities implemented, with room for additional features.

5. **Integration and System Testing**
   - **Objective:** Ensure cohesive operation of all components under various scenarios.
   - **Progress:** 50% complete. Initial integration done, comprehensive testing required.

6. **Documentation and User Guides**
   - **Objective:** Offer detailed setup, configuration, and operational guidance.
   - **Progress:** 40% complete. Basic documentation available, extensive guides needed.

## Documentation and User Guides

This section offers detailed setup, configuration, and operational guidance to effectively utilize the Guardian Wrapper Project. It encompasses explanations of individual components, including the Go orchestration layer, which plays a crucial role in monitoring, logging, and dynamically responding to system calls.

### Go Orchestration Layer Detailed Guide

The Go orchestration layer serves as the central component for managing eBPF program interactions, WebSocket communications for real-time event streaming, and signal handling for graceful shutdowns. Below is an in-depth overview of its implementation:

- **Import Dependencies**
  - Standard Libraries: Utilized for basic I/O, logging, HTTP server management, and OS-level operations.
  - Third-party Libraries: mux for HTTP routing, websocket for WebSocket management, and bcc for eBPF interactions.
- **eBPF Program Loading and Attachment**
  - Function: loadEBPFProgram reads the eBPF program source, compiles it, and attaches it to the execve system call tracepoint.
  - Error Handling: Critical errors during eBPF operations result in immediate termination to prevent insecure states.
- **WebSocket Event Streaming Handler**
  - Function: eventWebSocket upgrades HTTP connections to WebSocket and streams eBPF event data to connected clients.
  - Concurrency: Utilizes goroutines to handle multiple WebSocket connections and event streams concurrently.
- **Alert Handling Over WebSocket**
  - Function: alertWebSocket listens on a channel for alerts and forwards them over WebSocket connections to clients, enabling real-time security notifications.
- **Signal Handling for Graceful Shutdown**
  - Implements signal listening for os.Interrupt and syscall.SIGTERM to gracefully terminate the server and cleanup resources.

- **Main Function Workflow**
  - **eBPF Program Initialization:** Loads and attaches the eBPF program at startup.
  - **HTTP Server Setup:** Configures routes and starts the HTTP server for client interactions.
  - **Graceful Shutdown Handling:** Waits for termination signals to cleanly exit the application.

### Getting Started

#### Prerequisites
- Linux operating system
- GCC compiler
- BLAKE3 library

#### Installation
```bash
# Clone the repository
git clone <repository_url>

# Compile the project
make all

# Install the application (optional)
sudo make install
Test Scenario: Monitoring and Reacting to execve Syscalls
Objective: Verify that GuardianWrap can monitor execve syscalls, log them immutably, add stack canaries, and dump the stack if specified syscalls are triggered.

Setup Environment

Compile eBPF Program: Follow the compilation steps outlined previously to compile the exec_logger.c eBPF program.
Prepare GuardianWrap Components: Ensure the C wrapper (main.c), Rust component (main.rs), and Go orchestration layer (main.go) are compiled and ready for execution. Make sure the eBPF bytecode is accessible to the GuardianWrap.
Write Test Script

Develop a test script that automates the execution of a test application under the GuardianWrap's supervision.


#!/bin/bash

# Path to the GuardianWrap executable and test application
GUARDIAN_WRAP="./guardianwrap"
TEST_APP="./test_app"
LOG_FILE="/var/log/guardianwrap.log"
STACK_DUMP_FILE="/var/log/guardianwrap_stack_dump.txt"

# Clean up log files
rm -f $LOG_FILE
rm -f $STACK_DUMP_FILE

# Start GuardianWrap with the test application
$GUARDIAN_WRAP $TEST_APP &

# Wait for the test application to complete
wait

# Check log file for execve syscall entries
if grep -q "execve" $LOG_FILE; then
    echo "Test Passed: execve syscalls logged."
else
    echo "Test Failed: execve syscalls not found in log."
    exit 1
fi

# Optionally, check for stack dumps if the test application triggers a monitored condition
if [ -f "$STACK_DUMP_FILE" ]; then
    echo "Stack dump created for monitored syscalls."
else
    echo "No stack dump file found; either not triggered or test failed."
fi

exit 0
```

Execute the Test
Run the test script and observe the output. Ensure your test application (test_app) performs actions that trigger execve syscalls, and optionally, actions that should trigger stack dumps based on your security policies.

```

chmod +x test_guardianwrap.sh
./test_guardianwrap.sh

```

Evaluate Results
Success Criteria: The test is successful if the execve syscalls are logged as expected and stack dumps are created for specified conditions.
Failure Analysis: If syscalls are not logged or stack dumps are not generated as expected, investigate the integration points between the eBPF program, C wrapper, Rust component, and Go orchestration layer. Ensure the eBPF program is correctly attached and monitoring syscalls, and that GuardianWrap components are correctly handling and logging events.
This test validates the integration and functionality of the GuardianWrap project components in a cohesive workflow, ensuring the system can monitor, log, and react to system calls in a sandboxed environment.
#!/usr/bin/perl

use strict;
use warnings;
use IPC::Open2;

# An example hook script to integrate Watchman
# (https://facebook.github.io/watchman/) with git to speed up detecting
# new and modified files.
#
# The hook is passed a version (currently 1) and a time in nanoseconds
# formatted as a string and outputs to stdout all files that have been
# modified since the given time. Paths must be relative to the root of
# the working tree and separated by a single NUL.
#
# To enable this hook, rename this file to "query-watchman" and set
# 'git config core.fsmonitor .git/hooks/query-watchman'
#
my ($version, $time) = @ARGV;

# Check the hook interface version

if ($version == 1) {
	# convert nanoseconds to seconds
	# subtract one second to make sure watchman will return all changes
	$time = int ($time / 1000000000) - 1;
} else {
	die "Unsupported query-fsmonitor hook version '$version'.\n" .
	    "Falling back to scanning...\n";
}

my $git_work_tree;
if ($^O =~ 'msys' || $^O =~ 'cygwin') {
	$git_work_tree = Win32::GetCwd();
	$git_work_tree =~ tr/\\/\//;
} else {
	require Cwd;
	$git_work_tree = Cwd::cwd();
}

my $retry = 1;

launch_watchman();

sub launch_watchman {

	my $pid = open2(\*CHLD_OUT, \*CHLD_IN, 'watchman -j --no-pretty')
	    or die "open2() failed: $!\n" .
	    "Falling back to scanning...\n";

	# In the query expression below we're asking for names of files that
	# changed since $time but were not transient (ie created after
	# $time but no longer exist).
	#
	# To accomplish this, we're using the "since" generator to use the
	# recency index to select candidate nodes and "fields" to limit the
	# output to file names only.

	my $query = <<"	END";
		["query", "$git_work_tree", {
			"since": $time,
			"fields": ["name"]
		}]
	END

	print CHLD_IN $query;
	close CHLD_IN;
	my $response = do {local $/; <CHLD_OUT>};

	die "Watchman: command returned no output.\n" .
	    "Falling back to scanning...\n" if $response eq "";
	die "Watchman: command returned invalid output: $response\n" .
	    "Falling back to scanning...\n" unless $response =~ /^\{/;

	my $json_pkg;
	eval {
		require JSON::XS;
		$json_pkg = "JSON::XS";
		1;
	} or do {
		require JSON::PP;
		$json_pkg = "JSON::PP";
	};

	my $o = $json_pkg->new->utf8->decode($response);

	if ($retry > 0 and $o->{error} and $o->{error} =~ m/unable to resolve root .* directory (.*) is not watched/) {
		print STDERR "Adding '$git_work_tree' to watchman's watch list.\n";
		$retry--;
		qx/watchman watch "$git_work_tree"/;
		die "Failed to make watchman watch '$git_work_tree'.\n" .
		    "Falling back to scanning...\n" if $? != 0;

		# Watchman will always return all files on the first query so
		# return the fast "everything is dirty" flag to git and do the
		# Watchman query just to get it over with now so we won't pay
		# the cost in git to look up each individual file.
		print "/\0";
		eval { launch_watchman() };
		exit 0;
	}

	die "Watchman: $o->{error}.\n" .
	    "Falling back to scanning...\n" if $o->{error};

	binmode STDOUT, ":utf8";
	local $, = "\0";
	print @{$o->{files}};
}
#!/bin/sh
#
# An example hook script to block unannotated tags from entering.
# Called by "git receive-pack" with arguments: refname sha1-old sha1-new
#
# To enable this hook, rename this file to "update".
#
# Config
# ------
# hooks.allowunannotated
#   This boolean sets whether unannotated tags will be allowed into the
#   repository.  By default they won't be.
# hooks.allowdeletetag
#   This boolean sets whether deleting tags will be allowed in the
#   repository.  By default they won't be.
# hooks.allowmodifytag
#   This boolean sets whether a tag may be modified after creation. By default
#   it won't be.
# hooks.allowdeletebranch
#   This boolean sets whether deleting branches will be allowed in the
#   repository.  By default they won't be.
# hooks.denycreatebranch
#   This boolean sets whether remotely creating branches will be denied
#   in the repository.  By default this is allowed.
#

# --- Command line
refname="$1"
oldrev="$2"
newrev="$3"

# --- Safety check
if [ -z "$GIT_DIR" ]; then
	echo "Don't run this script from the command line." >&2
	echo " (if you want, you could supply GIT_DIR then run" >&2
	echo "  $0 <ref> <oldrev> <newrev>)" >&2
	exit 1
fi

if [ -z "$refname" -o -z "$oldrev" -o -z "$newrev" ]; then
	echo "usage: $0 <ref> <oldrev> <newrev>" >&2
	exit 1
fi

# --- Config
allowunannotated=$(git config --bool hooks.allowunannotated)
allowdeletebranch=$(git config --bool hooks.allowdeletebranch)
denycreatebranch=$(git config --bool hooks.denycreatebranch)
allowdeletetag=$(git config --bool hooks.allowdeletetag)
allowmodifytag=$(git config --bool hooks.allowmodifytag)

# check for no description
projectdesc=$(sed -e '1q' "$GIT_DIR/description")
case "$projectdesc" in
"Unnamed repository"* | "")
	echo "*** Project description file hasn't been set" >&2
	exit 1
	;;
esac

# --- Check types
# if $newrev is 0000...0000, it's a commit to delete a ref.
zero="0000000000000000000000000000000000000000"
if [ "$newrev" = "$zero" ]; then
	newrev_type=delete
else
	newrev_type=$(git cat-file -t $newrev)
fi

case "$refname","$newrev_type" in
	refs/tags/*,commit)
		# un-annotated tag
		short_refname=${refname##refs/tags/}
		if [ "$allowunannotated" != "true" ]; then
			echo "*** The un-annotated tag, $short_refname, is not allowed in this repository" >&2
			echo "*** Use 'git tag [ -a | -s ]' for tags you want to propagate." >&2
			exit 1
		fi
		;;
	refs/tags/*,delete)
		# delete tag
		if [ "$allowdeletetag" != "true" ]; then
			echo "*** Deleting a tag is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/tags/*,tag)
		# annotated tag
		if [ "$allowmodifytag" != "true" ] && git rev-parse $refname > /dev/null 2>&1
		then
			echo "*** Tag '$refname' already exists." >&2
			echo "*** Modifying a tag is not allowed in this repository." >&2
			exit 1
		fi
		;;
	refs/heads/*,commit)
		# branch
		if [ "$oldrev" = "$zero" -a "$denycreatebranch" = "true" ]; then
			echo "*** Creating a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/heads/*,delete)
		# delete branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	refs/remotes/*,commit)
		# tracking branch
		;;
	refs/remotes/*,delete)
		# delete tracking branch
		if [ "$allowdeletebranch" != "true" ]; then
			echo "*** Deleting a tracking branch is not allowed in this repository" >&2
			exit 1
		fi
		;;
	*)
		# Anything else (is there anything else?)
		echo "*** Update hook: unknown type of update to ref $refname of type $newrev_type" >&2
		exit 1
		;;
esac

# --- Finished
exit 0
#!/bin/sh
#
# An example hook script to verify what is about to be committed
# by applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-applypatch".

. git-sh-setup
precommit="$(git rev-parse --git-path hooks/pre-commit)"
test -x "$precommit" && exec "$precommit" ${1+"$@"}
:
#!/bin/sh

# An example hook script to verify what is about to be pushed.  Called by "git
# push" after it has checked the remote status, but before anything has been
# pushed.  If this script exits with a non-zero status nothing will be pushed.
#
# This hook is called with the following parameters:
#
# $1 -- Name of the remote to which the push is being done
# $2 -- URL to which the push is being done
#
# If pushing without using a named remote those arguments will be equal.
#
# Information about the commits which are being pushed is supplied as lines to
# the standard input in the form:
#
#   <local ref> <local sha1> <remote ref> <remote sha1>
#
# This sample shows how to prevent push of commits where the log message starts
# with "WIP" (work in progress).

remote="$1"
url="$2"

z40=0000000000000000000000000000000000000000

while read local_ref local_sha remote_ref remote_sha
do
	if [ "$local_sha" = $z40 ]
	then
		# Handle delete
		:
	else
		if [ "$remote_sha" = $z40 ]
		then
			# New branch, examine all commits
			range="$local_sha"
		else
			# Update to existing branch, examine new commits
			range="$remote_sha..$local_sha"
		fi

		# Check for WIP commit
		commit=`git rev-list -n 1 --grep '^WIP' "$range"`
		if [ -n "$commit" ]
		then
			echo >&2 "Found WIP commit in $local_ref, not pushing"
			exit 1
		fi
	fi
done

exit 0
#!/bin/sh
#
# An example hook script to make use of push options.
# The example simply echoes all push options that start with 'echoback='
# and rejects all pushes when the "reject" push option is used.
#
# To enable this hook, rename this file to "pre-receive".

if test -n "$GIT_PUSH_OPTION_COUNT"
then
	i=0
	while test "$i" -lt "$GIT_PUSH_OPTION_COUNT"
	do
		eval "value=\$GIT_PUSH_OPTION_$i"
		case "$value" in
		echoback=*)
			echo "echo from the pre-receive-hook: ${value#*=}" >&2
			;;
		reject)
			exit 1
		esac
		i=$((i + 1))
	done
fi
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git merge" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message to
# stderr if it wants to stop the merge commit.
#
# To enable this hook, rename this file to "pre-merge-commit".

. git-sh-setup
test -x "$GIT_DIR/hooks/pre-commit" &&
        exec "$GIT_DIR/hooks/pre-commit"
:
#!/bin/sh
#
# An example hook script to check the commit log message taken by
# applypatch from an e-mail message.
#
# The hook should exit with non-zero status after issuing an
# appropriate message if it wants to stop the commit.  The hook is
# allowed to edit the commit message file.
#
# To enable this hook, rename this file to "applypatch-msg".

. git-sh-setup
commitmsg="$(git rev-parse --git-path hooks/commit-msg)"
test -x "$commitmsg" && exec "$commitmsg" ${1+"$@"}
:
#!/bin/sh
#
# An example hook script to verify what is about to be committed.
# Called by "git commit" with no arguments.  The hook should
# exit with non-zero status after issuing an appropriate message if
# it wants to stop the commit.
#
# To enable this hook, rename this file to "pre-commit".

if git rev-parse --verify HEAD >/dev/null 2>&1
then
	against=HEAD
else
	# Initial commit: diff against an empty tree object
	against=$(git hash-object -t tree /dev/null)
fi

# If you want to allow non-ASCII filenames set this variable to true.
allownonascii=$(git config --bool hooks.allownonascii)

# Redirect output to stderr.
exec 1>&2

# Cross platform projects tend to avoid non-ASCII filenames; prevent
# them from being added to the repository. We exploit the fact that the
# printable range starts at the space character and ends with tilde.
if [ "$allownonascii" != "true" ] &&
	# Note that the use of brackets around a tr range is ok here, (it's
	# even required, for portability to Solaris 10's /usr/bin/tr), since
	# the square bracket bytes happen to fall in the designated range.
	test $(git diff --cached --name-only --diff-filter=A -z $against |
	  LC_ALL=C tr -d '[ -~]\0' | wc -c) != 0
then
	cat <<\EOF
Error: Attempt to add a non-ASCII file name.

This can cause problems if you want to work with people on other platforms.

To be portable it is advisable to rename the file.

If you know what you are doing you can disable this check using:

  git config hooks.allownonascii true
EOF
	exit 1
fi

# If there are whitespace errors, print the offending file names and fail.
exec git diff-index --check --cached $against --
#!/bin/sh
#
# An example hook script to prepare the commit log message.
# Called by "git commit" with the name of the file that has the
# commit message, followed by the description of the commit
# message's source.  The hook's purpose is to edit the commit
# message file.  If the hook fails with a non-zero status,
# the commit is aborted.
#
# To enable this hook, rename this file to "prepare-commit-msg".

# This hook includes three examples. The first one removes the
# "# Please enter the commit message..." help message.
#
# The second includes the output of "git diff --name-status -r"
# into the message, just before the "git status" output.  It is
# commented because it doesn't cope with --amend or with squashed
# commits.
#
# The third example adds a Signed-off-by line to the message, that can
# still be edited.  This is rarely a good idea.

COMMIT_MSG_FILE=$1
COMMIT_SOURCE=$2
SHA1=$3

/usr/bin/perl -i.bak -ne 'print unless(m/^. Please enter the commit message/..m/^#$/)' "$COMMIT_MSG_FILE"

# case "$COMMIT_SOURCE,$SHA1" in
#  ,|template,)
#    /usr/bin/perl -i.bak -pe '
#       print "\n" . `git diff --cached --name-status -r`
# 	 if /^#/ && $first++ == 0' "$COMMIT_MSG_FILE" ;;
#  *) ;;
# esac

# SOB=$(git var GIT_COMMITTER_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# git interpret-trailers --in-place --trailer "$SOB" "$COMMIT_MSG_FILE"
# if test -z "$COMMIT_SOURCE"
# then
#   /usr/bin/perl -i.bak -pe 'print "\n" if !$first_line++' "$COMMIT_MSG_FILE"
# fi
#!/bin/sh
#
# An example hook script to check the commit log message.
# Called by "git commit" with one argument, the name of the file
# that has the commit message.  The hook should exit with non-zero
# status after issuing an appropriate message if it wants to stop the
# commit.  The hook is allowed to edit the commit message file.
#
# To enable this hook, rename this file to "commit-msg".

# Uncomment the below to add a Signed-off-by line to the message.
# Doing this in a hook is a bad idea in general, but the prepare-commit-msg
# hook is more suited to it.
#
# SOB=$(git var GIT_AUTHOR_IDENT | sed -n 's/^\(.*>\).*$/Signed-off-by: \1/p')
# grep -qs "^$SOB" "$1" || echo "$SOB" >> "$1"

# This example catches duplicate Signed-off-by lines.

test "" = "$(grep '^Signed-off-by: ' "$1" |
	 sort | uniq -c | sed -e '/^[ 	]*1[ 	]/d')" || {
	echo >&2 Duplicate Signed-off-by lines.
	exit 1
}
#!/bin/sh
#
# An example hook script to prepare a packed repository for use over
# dumb transports.
#
# To enable this hook, rename this file to "post-update".

exec git update-server-info
#!/bin/sh
#
# Copyright (c) 2006, 2008 Junio C Hamano
#
# The "pre-rebase" hook is run just before "git rebase" starts doing
# its job, and can prevent the command from running by exiting with
# non-zero status.
#
# The hook is called with the following parameters:
#
# $1 -- the upstream the series was forked from.
# $2 -- the branch being rebased (or empty when rebasing the current branch).
#
# This sample shows how to prevent topic branches that are already
# merged to 'next' branch from getting rebased, because allowing it
# would result in rebasing already published history.

publish=next
basebranch="$1"
if test "$#" = 2
then
	topic="refs/heads/$2"
else
	topic=`git symbolic-ref HEAD` ||
	exit 0 ;# we do not interrupt rebasing detached HEAD
fi

case "$topic" in
refs/heads/??/*)
	;;
*)
	exit 0 ;# we do not interrupt others.
	;;
esac

# Now we are dealing with a topic branch being rebased
# on top of master.  Is it OK to rebase it?

# Does the topic really exist?
git show-ref -q "$topic" || {
	echo >&2 "No such branch $topic"
	exit 1
}

# Is topic fully merged to master?
not_in_master=`git rev-list --pretty=oneline ^master "$topic"`
if test -z "$not_in_master"
then
	echo >&2 "$topic is fully merged to master; better remove it."
	exit 1 ;# we could allow it, but there is no point.
fi

# Is topic ever merged to next?  If so you should not be rebasing it.
only_next_1=`git rev-list ^master "^$topic" ${publish} | sort`
only_next_2=`git rev-list ^master           ${publish} | sort`
if test "$only_next_1" = "$only_next_2"
then
	not_in_topic=`git rev-list "^$topic" master`
	if test -z "$not_in_topic"
	then
		echo >&2 "$topic is already up to date with master"
		exit 1 ;# we could allow it, but there is no point.
	else
		exit 0
	fi
else
	not_in_next=`git rev-list --pretty=oneline ^${publish} "$topic"`
	/usr/bin/perl -e '
		my $topic = $ARGV[0];
		my $msg = "* $topic has commits already merged to public branch:\n";
		my (%not_in_next) = map {
			/^([0-9a-f]+) /;
			($1 => 1);
		} split(/\n/, $ARGV[1]);
		for my $elem (map {
				/^([0-9a-f]+) (.*)$/;
				[$1 => $2];
			} split(/\n/, $ARGV[2])) {
			if (!exists $not_in_next{$elem->[0]}) {
				if ($msg) {
					print STDERR $msg;
					undef $msg;
				}
				print STDERR " $elem->[1]\n";
			}
		}
	' "$topic" "$not_in_next" "$not_in_master"
	exit 1
fi

<<\DOC_END

This sample hook safeguards topic branches that have been
published from being rewound.

The workflow assumed here is:

 * Once a topic branch forks from "master", "master" is never
   merged into it again (either directly or indirectly).

 * Once a topic branch is fully cooked and merged into "master",
   it is deleted.  If you need to build on top of it to correct
   earlier mistakes, a new topic branch is created by forking at
   the tip of the "master".  This is not strictly necessary, but
   it makes it easier to keep your history simple.

 * Whenever you need to test or publish your changes to topic
   branches, merge them into "next" branch.

The script, being an example, hardcodes the publish branch name
to be "next", but it is trivial to make it configurable via
$GIT_DIR/config mechanism.

With this workflow, you would want to know:

(1) ... if a topic branch has ever been merged to "next".  Young
    topic branches can have stupid mistakes you would rather
    clean up before publishing, and things that have not been
    merged into other branches can be easily rebased without
    affecting other people.  But once it is published, you would
    not want to rewind it.

(2) ... if a topic branch has been fully merged to "master".
    Then you can delete it.  More importantly, you should not
    build on top of it -- other people may already want to
    change things related to the topic as patches against your
    "master", so if you need further changes, it is better to
    fork the topic (perhaps with the same name) afresh from the
    tip of "master".

Let's look at this example:

		   o---o---o---o---o---o---o---o---o---o "next"
		  /       /           /           /
		 /   a---a---b A     /           /
		/   /               /           /
	       /   /   c---c---c---c B         /
	      /   /   /             \         /
	     /   /   /   b---b C     \       /
	    /   /   /   /             \     /
    ---o---o---o---o---o---o---o---o---o---o---o "master"


A, B and C are topic branches.

 * A has one fix since it was merged up to "next".

 * B has finished.  It has been fully merged up to "master" and "next",
   and is ready to be deleted.

 * C has not merged to "next" at all.

We would want to allow C to be rebased, refuse A, and encourage
B to be deleted.

To compute (1):

	git rev-list ^master ^topic next
	git rev-list ^master        next

	if these match, topic has not merged in next at all.

To compute (2):

	git rev-list master..topic

	if this is empty, it is fully merged to "master".

DOC_END
#include <uapi/linux/ptrace.h>
#include <linux/sched.h>
#include <linux/fs.h>

struct file_op_event_t {
    u32 pid;
    char comm[TASK_COMM_LEN];
    char filename[256];
    char operation[10]; // "open" or "unlink"
};

BPF_PERF_OUTPUT(file_op_events);

// Tracepoint for open
TRACEPOINT_PROBE(syscalls, sys_enter_open) {
    struct file_op_event_t data = {};
    const char __user *filename;
    bpf_probe_read(&filename, sizeof(filename), &args->filename);
    bpf_probe_read_str(&data.filename, sizeof(data.filename), filename);
    data.pid = bpf_get_current_pid_tgid() >> 32;
    bpf_get_current_comm(&data.comm, sizeof(data.comm));
    bpf_probe_read_str(&data.operation, sizeof(data.operation), "open");
    
    file_op_events.perf_submit(args, &data, sizeof(data));
    return 0;
}

// Tracepoint for unlink
TRACEPOINT_PROBE(syscalls, sys_enter_unlink) {
    struct file_op_event_t data = {};
    const char __user *pathname;
    bpf_probe_read(&pathname, sizeof(pathname), &args->pathname);
    bpf_probe_read_str(&data.filename, sizeof(data.filename), pathname);
    data.pid = bpf_get_current_pid_tgid() >> 32;
    bpf_get_current_comm(&data.comm, sizeof(data.comm));
    bpf_probe_read_str(&data.operation, sizeof(data.operation), "unlink");
    
    file_op_events.perf_submit(args, &data, sizeof(data));
    return 0;
}

extern crate bcc;
use bcc::perf_event::{Event, PerfMapBuilder};
use bcc::BccError;
use core::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;

// Structs representing the data structure of events we expect from eBPF.
#[repr(C)]
struct ExecveEvent {
    pid: u32,
    filename: [u8; 256], // Adjust size based on eBPF program
    argv: [u8; 256],     // Adjust size as needed
}

#[repr(C)]
struct FileOpEvent {
    pid: u32,
    comm: [u8; 16],
    filename: [u8; 256],
    operation: u32, // Could be an enum or similar representation
}

static RUNNING: AtomicBool = AtomicBool::new(true);

fn main() -> Result<(), BccError> {
    let code = include_str!("exec_logger.c");
    let mut module = bcc::BPF::new(code)?;

    bcc::Tracepoint::new(&mut module, "syscalls", "sys_enter_execve", "on_execve_enter")?.init()?;

    let table = module.table("execve_events")?;
    let perf_map = PerfMapBuilder::new(table, handle_event).build()?;

    println!("Listening for events. Press Ctrl+C to stop.");

    let running = Arc::new(RUNNING);
    ctrlc::set_handler(move || {
        running.store(false, Ordering::SeqCst);
    })?;

    while running.load(Ordering::SeqCst) {
        perf_map.poll(200);
    }

    println!("Exiting...");
    Ok(())
}

fn handle_event(event: Event) {
    if let Ok(data) = event.data() {
        if event.name == "execve_events" {
            if let Ok(exec_event) = parse_execve_event(&data) {
                println!("Execve Event - PID: {}, Filename: {}, Args: {}",
                         exec_event.pid,
                         String::from_utf8_lossy(&exec_event.filename),
                         String::from_utf8_lossy(&exec_event.argv));
            }
        } else if event.name == "file_op_events" {
            if let Ok(file_event) = parse_file_op_event(&data) {
                println!("File Operation Event - PID: {}, Comm: {}, Operation: {}, Filename: {}",
                         file_event.pid,
                         String::from_utf8_lossy(&file_event.comm),
                         file_event.operation, // This would be more descriptive with an enum
                         String::from_utf8_lossy(&file_event.filename));
            }
        }
    }
}

fn parse_execve_event(data: &[u8]) -> Result<ExecveEvent, &'static str> {
    if data.len() != std::mem::size_of::<ExecveEvent>() {
        return Err("Incorrect data size for execve event");
    }
    let execve_event: ExecveEvent = unsafe { std::ptr::read(data.as_ptr() as *const _) };
    Ok(execve_event)
}

fn parse_file_op_event(data: &[u8]) -> Result<FileOpEvent, &'static str> {
    if data.len() != std::mem::size_of::<FileOpEvent>() {
        return Err("Incorrect data size for file operation event");
    }
    let file_op_event: FileOpEvent = unsafe { std::ptr::read(data.as_ptr() as *const _) };
    Ok(file_op_event)
}

Name: guardian-wrapper
Version: 1.0
Release: 1
Summary: A guardian wrapper for Linux applications with enhanced security features
License: GPL
Source: %{name}-%{version}.tar.gz
BuildRequires: gcc, make, liboqs-devel, openssl-devel
Requires: liboqs, openssl

%description
Guardian wrapper enhances Linux application security with stack canary monitoring,
secure and immutable logging using BLAKE3, and real-time monitoring capabilities.

%prep
%setup -q

%build
make %{?_smp_mflags}

%install
rm -rf $RPM_BUILD_ROOT
make install DESTDIR=$RPM_BUILD_ROOT

%files
%defattr(-,root,root,-)
/usr/local/bin/guardian-wrapper

%pre
# Commands to run before installation, e.g., checking for dependencies

%post
# Commands to run after installation, e.g., setting up environment variables

%preun
# Commands to run before uninstallation

%postun
# Commands to run after uninstallation

%changelog
* Date Author - Version-Release
- Initial RPM release

#!/bin/bash

# Path to the GuardianWrap executable and test application
GUARDIAN_WRAP="./guardianwrap" # Assume this is the compiled binary of the C wrapper
TEST_APP="./test_app" # A simple application that triggers different syscalls
LOG_FILE="/var/log/guardianwrap.log"
STACK_DUMP_FILE="/var/log/guardianwrap_stack_dump.txt"

# Clean up log files
rm -f $LOG_FILE
rm -f $STACK_DUMP_FILE

# Start GuardianWrap with the test application
$GUARDIAN_WRAP $TEST_APP &

# Wait for the test application to complete
wait

# Check log file for execve syscall entries
if grep -q "execve" $LOG_FILE; then
    echo "Test Passed: execve syscalls logged."
else
    echo "Test Failed: execve syscalls not found in log."
    exit 1
fi

# Optionally, check for stack dumps if the test application triggers a monitored condition
if [ -f "$STACK_DUMP_FILE" ]; then
    echo "Stack dump created for monitored syscalls."
else
    echo "No stack dump file found; either not triggered or test failed."
fi

exit 0

